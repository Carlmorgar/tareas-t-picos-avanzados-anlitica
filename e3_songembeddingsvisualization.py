# -*- coding: utf-8 -*-
"""E3-SongEmbeddingsVisualization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KO6k-TUBT2pIaiZ7N3XdyxiUaMm_BCyb

<a href="https://colab.research.google.com/github/sergiomora03/AdvancedTopicsAnalytics/blob/main/exercises/E3-SongEmbeddingsVisualization.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## Song Embeddings - Skipgram Recommender

In this notebook, we'll use human-made music playlists to learn song embeddings. We'll treat a playlist as if it's a sentence and the songs it contains as words. We feed that to the word2vec algorithm which then learns embeddings for every song we have. These embeddings can then be used to recommend similar songs. This technique is used by Spotify, AirBnB, Alibaba, and others. It accounts for a vast portion of their user activity, user media consumption, and/or sales (in the case of Alibaba).

The [dataset we'll use](https://www.cs.cornell.edu/~shuochen/lme/data_page.html) was collected by Shuo Chen from Cornell University. The dataset contains playlists from hundreds of radio stations from around the US.

## Importing packages and dataset
"""

import numpy as np
import pandas as pd
import gensim
from gensim.models import Word2Vec
from urllib import request
import warnings
warnings.filterwarnings('ignore')

"""The playlist dataset is a text file where every line represents a playlist. That playlist is basically a series of song IDs."""

# Se obtiene la plaaylist de una url
data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')

# Se analiza el archivo del conjunto de datos de la lista de reproducción. Salta las dos primeras líneas como
# ellos solamente contiene metadata
lines = data.read().decode("utf-8").split('\n')[2:]

# Se eliminan la listas de reproducción con una sola canción
playlists = [s.rstrip().split() for s in lines if len(s.split()) > 1]

"""The `playlists` variable now contains a python list. Each item in this list is a playlist containing song ids. We can look at the first two playlists here:"""

print( 'Playlist #1:\n ', playlists[0], '\n')
print( 'Playlist #2:\n ', playlists[1])

"""## Entrenando el modelo de Word2Vec
El conjunto de datos ahora tiene la forma que el modelo Word2Vec espera como entrada. Pasamos el conjunto de datos al modelo.
"""

# Se crea un modelo Word2Vec utilizando un corpus de texto representado por la variable playlists con un tamaño de 32 palabras el vector, una ventana de 20 palabras para dar contexto, 50 muestra negativas y que al menos una palabra debe tener en el corpus para ser considerada durante el entrenamiento
model = Word2Vec(playlists, vector_size=32, window=20, negative=50, min_count=1, workers=4)

"""The model is now trained. Every song has an embedding. We only have song IDs, though, no titles or other info. Let's grab the song information file.

## Song Title and Artist File
Let's load and parse the file containing song titles and artists
"""

songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')
songs_file = songs_file.read().decode("utf-8").split('\n')
songs = [s.rstrip().split('\t') for s in songs_file]

songs_df = pd.DataFrame(data=songs, columns = ['id', 'title', 'artist'])
songs_df = songs_df.set_index('id')

songs_df.head()

"""### Exercise:

Build visualization for the embeddings of the song recommender.
"""

import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

"""
Pre-procesamiento
"""

#Se hace el preprocesamiento del modelo de vocabulario para hacer las visualizaciones

words_vocab= list(model.wv.key_to_index.keys())#Se toman todas las palabras del vocabulario
print("Size of Vocabulary:",len(words_vocab))
print("Few words in Vocabulary",words_vocab[:50])

#Se eliminan los stopword para que la visualización sea más limpia
stopwords_en = stopwords.words()
words_vocab_without_sw = [word.lower() for word in words_vocab if not word in stopwords_en]
print("Size of Vocabulary without stopwords:",len(words_vocab_without_sw))
print("Few words in Vocabulary without stopwords",words_vocab_without_sw[:30])
#The size didnt reduce much after removing the stop words so lets try visualizing only a selected subset of words

# Se busca palabras similares para cada palabra en la serie keys utilizando un modelo Word2Vec (model.wv) y almacena las palabras similares y sus embeddings correspondientes en word_clusters y embedding_clusters, respectivamente. Además, cuenta cuántas palabras en keys están presentes en el vocabulario del modelo

keys = songs_df['title']
topn = 30
embedding_clusters = []
word_clusters = []
c=0
c0 = 0
for word in keys:
    c0=c0+1
    if word in list(model.wv.key_to_index.keys()):  # Verificamos si la palabra está presente en el vocabulario del modelo
        c=c+1
        embeddings = []
        words = []
        for similar_word, _ in model.wv.most_similar(word, topn=30):
            words.append(similar_word)
            embeddings.append(model.wv[similar_word])
        embedding_clusters.append(embeddings)
        word_clusters.append(words)

print(c)
print(c0)

"""
Conversion a 2d
"""

from sklearn.manifold import TSNE
import numpy as np

embedding_clusters = np.array(embedding_clusters)
n, m, k = embedding_clusters.shape #geting the dimensions
tsne_model_en_2d = TSNE(perplexity=5, n_components=2, init='pca', n_iter=1500, random_state=2020)
embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2) #reshaping it into 2d so we can visualize it

# Commented out IPython magic to ensure Python compatibility.
"""
Hyperparameters of TSNE
1. n_components: The number of components, i.e., the dimension of the value space
2. perplexity: The number of effective neighbours
3. n_iter: Maximum number of iterations for the optimization.
4. init: Initialization of embedding.

t-SNE requires good amount of hyperparameter tuning to give effective results.
More details on the hyperparameters can be found in the official [docs]
(https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).
It is very easy to misread tsne too. This [article](https://distill.pub/2016/misread-tsne/)
provides more deatils about it.

"""


from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
# %matplotlib inline

#script para construir graficos bidimensionales usando Matplotlib
def tsne_plot_similar_words(labels, embedding_clusters, word_clusters, a=0.7):
    plt.figure(figsize=(16, 9))


    for label, embeddings, words in zip(labels, embedding_clusters, word_clusters):
        x = embeddings[:,0]
        y = embeddings[:,1]
        plt.scatter(x, y, alpha=a, label=label)
        for i, word in enumerate(words):
            plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2),
                         textcoords='offset points', ha='right', va='bottom', size=8)
    plt.legend(loc=4)
    plt.grid(True)
    plt.show()



tsne_plot_similar_words(words_vocab_without_sw, embeddings_en_2d, word_clusters)